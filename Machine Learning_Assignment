{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.decomposition import PCA # PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "data = pd.read_csv(\"project_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 첫번째 분석 방법\n",
    "\n",
    "### 1) 이상치 제거\n",
    "### 2) 정규화\n",
    "### 3) PCA\n",
    "### 4) 로지스틱을 이용한 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value - mean의 절대값이 5시그마 밖의 값이면 이상치라 가정하고 제거\n",
    "for i in data1.iloc[:,1:30]:\n",
    "    data1 = data1[~(abs(data1[i] - data1[i].mean()) > 5*data1[i].std())] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y로 나누고 X값들을 정규화\n",
    "X = data1.iloc[:,1:30]\n",
    "Y = data1.iloc[:,30]\n",
    "for i in X:\n",
    "    X[i] = (X[i] - X[i].mean())/X[i].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.623337, 14.352209, 20.633861, 26.349525, 31.617967, 36.534743,\n",
       "        41.3223  , 45.939378, 50.463384, 54.809141, 59.039765, 63.003636,\n",
       "        66.77815 , 70.394455, 73.951452, 77.480637, 80.995487, 84.416027,\n",
       "        87.800113, 90.622305, 92.593778, 94.37697 , 95.80591 , 97.172102,\n",
       "        98.294107, 99.189599, 99.956628, 99.997534, 99.999998]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA\n",
    "pca_num = PCA(n_components=29)\n",
    "X_PCA_T = pca_num.fit_transform(X)\n",
    "X_PCA = pca_num.fit(X)\n",
    "\n",
    "X_PCA_sum = np.cumsum(np.round(X_PCA.explained_variance_ratio_, decimals=8)*100) \n",
    "X_PCA_sum_varc = np.array(np.transpose(X_PCA_sum[:,np.newaxis])) \n",
    "\n",
    "X_PCA_sum_varc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 결과에서 17번까지의 특징을 이용하면 전체 데이터의 80%를 설명할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_y = np.c_[X_PCA_T,Y]\n",
    "# 데이터프레임으로 변경\n",
    "Data = pd.DataFrame(pc_y)\n",
    "\n",
    "X = Data.iloc[:,0:17]\n",
    "Y = Data.iloc[:,29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunni\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     93351\n",
      "         1.0       0.00      0.00      0.00        28\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     93379\n",
      "   macro avg       0.50      0.50      0.50     93379\n",
      "weighted avg       1.00      1.00      1.00     93379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunni\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.5,random_state=1)\n",
    "\n",
    "Log = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "Log_target_predict = Log.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, Log_target_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 결과를 봤을 때 어떤 데이터를 넣어도 Class = 0으로 예측을 한 것을 알 수 있다.\n",
    "\n",
    "결과적으로 Class가 1인 데이터를 하나도 분류하지 못했다.\n",
    "\n",
    "- 발견한 것 : 이상치 제거할 때 Class 값이 1인 데이터들이 많이 사라진 것을 발견"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 두번째 분석 방법\n",
    "\n",
    "### 1) 정규화\n",
    "### 2) PCA\n",
    "### 3) 로지스틱을 이용한 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y로 나누고 X값들을 정규화\n",
    "X = data2.iloc[:,1:30]\n",
    "Y = data2.iloc[:,30]\n",
    "for i in X:\n",
    "    X[i] = (X[i] - X[i].mean())/X[i].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.821957,  10.472614,  14.054332,  17.581883,  21.059338,\n",
       "         24.534958,  28.005411,  31.473655,  34.935393,  38.39431 ,\n",
       "         41.84903 ,  45.301213,  48.746796,  52.188403,  55.628551,\n",
       "         59.061438,  62.492848,  65.919956,  69.344699,  72.766799,\n",
       "         76.186152,  79.598404,  83.005469,  86.410194,  89.806455,\n",
       "         93.191683,  96.556926,  99.865013, 100.      ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA\n",
    "pca_num = PCA(n_components=29)\n",
    "X_PCA_T = pca_num.fit_transform(X)\n",
    "X_PCA = pca_num.fit(X)\n",
    "\n",
    "X_PCA_sum = np.cumsum(np.round(X_PCA.explained_variance_ratio_, decimals=8)*100) \n",
    "X_PCA_sum_varc = np.array(np.transpose(X_PCA_sum[:,np.newaxis])) \n",
    "\n",
    "X_PCA_sum_varc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 결과에서 23번까지의 특징을 이용하면 전체 데이터의 80%를 설명할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_y = np.c_[X_PCA_T,Y]\n",
    "# 데이터프레임으로 변경\n",
    "Data = pd.DataFrame(pc_y)\n",
    "\n",
    "X = Data.iloc[:,0:23]\n",
    "Y = Data.iloc[:,29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunni\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     99501\n",
      "         1.0       0.79      0.58      0.67       181\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.89      0.79      0.83     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.5,random_state=1)\n",
    "\n",
    "Log = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "y_pred = Log.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[99473,    28],\n",
       "       [   76,   105]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 결과를 봤을 때 Class = 1인 데이터를 받았을때 1이라고 할 확률이 58%이므로 좋지도 나쁘지도 않은 결과이다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 세번째 분석 방법\n",
    "\n",
    "### 1) 정규화\n",
    "### 2) 로지스틱을 이용한 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y로 나누고 X값들을 정규화\n",
    "X = data3.iloc[:,1:30]\n",
    "Y = data3.iloc[:,30]\n",
    "for i in X:\n",
    "    X[i] = (X[i] - X[i].mean())/X[i].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunni\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     99501\n",
      "           1       0.78      0.57      0.66       181\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.89      0.78      0.83     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.5,random_state=1)\n",
    "\n",
    "Log = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "y_pred = Log.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[99472,    29],\n",
       "       [   78,   103]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 결과를 봤을 때 Class = 1인 데이터를 받았을때 1이라고 할 확률이 57%이므로 PCA를 이용한 결과와 거의 동일하다고 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네번째 분석 방법\n",
    "\n",
    "### 1) 정규화\n",
    "### 2) 분산이 높은 특징 추출(직접)\n",
    "### 3) 로지스틱을 이용한 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y로 나누고 X값들을 정규화\n",
    "X = data4.iloc[:,1:30]\n",
    "Y = data4.iloc[:,30]\n",
    "for i in X:\n",
    "    X[i] = (X[i] - X[i].mean())/X[i].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Class   R-squared:                       0.511\n",
      "Model:                            OLS   Adj. R-squared:                  0.511\n",
      "Method:                 Least Squares   F-statistic:                     7193.\n",
      "Date:                Wed, 22 May 2019   Prob (F-statistic):               0.00\n",
      "Time:                        17:07:48   Log-Likelihood:             4.1946e+05\n",
      "No. Observations:              199364   AIC:                        -8.389e+05\n",
      "Df Residuals:                  199334   BIC:                        -8.385e+05\n",
      "Df Model:                          29                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0018   6.61e-05     27.013      0.000       0.002       0.002\n",
      "V1            -0.0037   8.55e-05    -42.981      0.000      -0.004      -0.004\n",
      "V2             0.0048      0.000     33.459      0.000       0.004       0.005\n",
      "V3            -0.0074   8.31e-05    -89.248      0.000      -0.008      -0.007\n",
      "V4             0.0054   7.02e-05     76.405      0.000       0.005       0.005\n",
      "V5            -0.0031      0.000    -26.895      0.000      -0.003      -0.003\n",
      "V6            -0.0022   8.39e-05    -26.291      0.000      -0.002      -0.002\n",
      "V7            -0.0085      0.000    -73.300      0.000      -0.009      -0.008\n",
      "V8             0.0009   7.04e-05     12.764      0.000       0.001       0.001\n",
      "V9            -0.0039    6.7e-05    -58.571      0.000      -0.004      -0.004\n",
      "V10           -0.0087   7.04e-05   -124.123      0.000      -0.009      -0.009\n",
      "V11            0.0063   6.61e-05     95.980      0.000       0.006       0.006\n",
      "V12           -0.0107   6.62e-05   -162.117      0.000      -0.011      -0.011\n",
      "V13           -0.0002   6.61e-05     -3.117      0.002      -0.000   -7.65e-05\n",
      "V14           -0.0126   6.66e-05   -188.628      0.000      -0.013      -0.012\n",
      "V15           -0.0002   6.61e-05     -2.866      0.004      -0.000   -5.99e-05\n",
      "V16           -0.0081   6.61e-05   -121.948      0.000      -0.008      -0.008\n",
      "V17           -0.0134   6.61e-05   -203.197      0.000      -0.014      -0.013\n",
      "V18           -0.0047   6.67e-05    -69.854      0.000      -0.005      -0.005\n",
      "V19            0.0015   6.74e-05     22.232      0.000       0.001       0.002\n",
      "V20            0.0002      0.000      1.706      0.088   -2.65e-05       0.000\n",
      "V21            0.0015   7.07e-05     20.915      0.000       0.001       0.002\n",
      "V22            0.0002   6.78e-05      2.270      0.023     2.1e-05       0.000\n",
      "V23          7.91e-05   7.07e-05      1.119      0.263   -5.94e-05       0.000\n",
      "V24           -0.0003   6.61e-05     -4.954      0.000      -0.000      -0.000\n",
      "V25            0.0003    6.7e-05      3.783      0.000       0.000       0.000\n",
      "V26            0.0002   6.61e-05      3.001      0.003    6.88e-05       0.000\n",
      "V27            0.0006   6.64e-05      9.356      0.000       0.000       0.001\n",
      "V28            0.0004   6.62e-05      5.603      0.000       0.000       0.001\n",
      "Amount         0.0021      0.000      8.575      0.000       0.002       0.003\n",
      "==============================================================================\n",
      "Omnibus:                   412366.463   Durbin-Watson:                   1.961\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):       5448815599.062\n",
      "Skew:                          17.078   Prob(JB):                         0.00\n",
      "Kurtosis:                     812.183   Cond. No.                         7.11\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "x2 = sm.add_constant(X)\n",
    "model = sm.OLS(Y,x2)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 결과에서 각 특징별 t값이 있는데 t값이 높다는 것은 그 특징이 유의미한 존재임을 말해준다.\n",
    "\n",
    "먼저 각 특징별 t값의 절댓값이 100이 넘는 특징을 선택해 분류해 보려고 한다.\n",
    "\n",
    "V10,V12,V14,V16,V17 다섯개의 특징만 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,[10,12,14,16,17]]\n",
    "Y = data.iloc[:,30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunni\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     99501\n",
      "           1       0.88      0.56      0.69       181\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.94      0.78      0.84     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.5,random_state=1)\n",
    "\n",
    "Log = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "y_pred = Log.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[99487,    14],\n",
       "       [   79,   102]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여전히 Class = 1인 데이터를 받았을때 1이라고 할 확률이 56%이므로 크게 달라진 점은 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다섯번째 분석 방법\n",
    "\n",
    "### 1) 정규화\n",
    "### 2) 분산이 높은 특징 추출(컴퓨터)\n",
    "### 3) 로지스틱을 이용한 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5 = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y로 나누고 X값들을 정규화\n",
    "X = data5.iloc[:,1:30]\n",
    "Y = data5.iloc[:,30]\n",
    "for i in X:\n",
    "    X[i] = (X[i] - X[i].mean())/X[i].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.5,random_state=1)\n",
    "Log = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False False  True False  True\n",
      " False  True False  True  True False False False False False False False\n",
      " False False False False False]\n",
      "[ 8  9  2  5 10 12  3 15  7  1  4  1 18  1 20  1  1  6 14 25 13 24 23 17\n",
      " 22 21 16 19 11]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR \n",
    "from sklearn.feature_selection import RFE \n",
    "from sklearn import datasets\n",
    "selector = RFE(Log, 5).fit(X_train, y_train) #  전체 특징 중 중요한 5개의 특징을 정해줌\n",
    "print(selector.support_) \n",
    "print(selector.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,[9,11,13,15,16]]\n",
    "Y = data.iloc[:,30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunni\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     99501\n",
      "           1       0.91      0.49      0.63       181\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     99682\n",
      "   macro avg       0.95      0.74      0.82     99682\n",
      "weighted avg       1.00      1.00      1.00     99682\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.5,random_state=1)\n",
    "\n",
    "Log = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "y_pred = Log.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[99492,     9],\n",
       "       [   93,    88]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class = 1인 데이터를 받았을때 1이라고 할 확률이 49%이므로 분석 결과가 더 낮아졌다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 여섯번째 분석 방법\n",
    "\n",
    "### 1) 정규화\n",
    "### 2) 직관적으로 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = X.iloc[:,30]\n",
    "y_pred = np.zeros((199364,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 문제는 Class 값이 1과 0을 구분하는 것이기 때문에 Class = 1과 0을 그룹화 한 뒤 각 특징별 분산의 차이를 확인했는데 V7,V8,V17의 분산이 차이가 많이 나는 것을 발견했습니다.\n",
    "\n",
    "그래서 위 세개의 특징 값으로 각 데이터 값을 비교해 봤더니 육안으로 차이가 존재하는 것을 확인했습니다.\n",
    "\n",
    "결과적으로 각 특징별 데이터 값을 가지고 제가 임의로 지정한 값 이상일 경우에는 모두 Class가 1로 간주했습니다.\n",
    "\n",
    "아래는 위에 말한 내용을 함수로 정리한 내용입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_Analysis_method(data):\n",
    "    b1 = set(data[abs(data.iloc[:,17]) > 1.5].index)\n",
    "    b2 = set(data[abs(data.iloc[:,7]) > 6].index)\n",
    "    b3 = set(data[abs(data.iloc[:,8]) > 6].index)\n",
    "\n",
    "    return b1 | b2 | b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = my_Analysis_method(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in result:\n",
    "    y_pred[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[190269,   8739],\n",
       "       [    60,    296]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98    199008\n",
      "           1       0.03      0.83      0.06       356\n",
      "\n",
      "   micro avg       0.96      0.96      0.96    199364\n",
      "   macro avg       0.52      0.89      0.52    199364\n",
      "weighted avg       1.00      0.96      0.98    199364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과적으로 실제 값이 Class가 1일 때 1로 예측할 확률이 83%로 증가하게 되었습니다.\n",
    "\n",
    "물론 위의 여러 결과물 보다 Accuracy가 떨어지지만 Class가 1인 데이터를 찾는것에 focus를 둔다면 위의 분석 방법들 보다 이상적인 분석방법이라 할 수 있다고 생각합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
